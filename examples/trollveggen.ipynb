{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9b6d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/Documents/masters/gaussian-process-kan/.venv/lib/python3.12/site-packages/cola/backends/backends.py:75: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(cls, tree_flatten, tree_unflatten)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import jax \n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gpkan.gpKAN import GPKAN\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use([ 'science', \"grid\" ])\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "key = jr.key(123)\n",
    "px = 1/plt.rcParams['figure.dpi']\n",
    "plt.rcParams.update({'axes.titlesize': 18})\n",
    "plt.rcParams.update({'axes.labelsize': 15})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc5b45",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trollveggen_df = pd.read_csv('../datasets/troll3.csv')\n",
    "print(trollveggen_df.shape)\n",
    "trollveggen = jnp.array(trollveggen_df.values)\n",
    "function_name = \"trollveggen\"\n",
    "\n",
    "print(jnp.min(trollveggen[:, 0]), jnp.max(trollveggen[:, 0]))\n",
    "print(jnp.min(trollveggen[:, 1]), jnp.max(trollveggen[:, 1]))\n",
    "print(jnp.min(trollveggen[:, 2]), jnp.max(trollveggen[:, 2]))\n",
    "print(jnp.unique(trollveggen[:, 0]).shape)\n",
    "print(jnp.unique(trollveggen[:, 1]).shape)\n",
    "print(trollveggen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(trollveggen[:, 0],trollveggen[:, 1], c=trollveggen[:, 2])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b96d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = 7.55, 7.96\n",
    "# y_min, y_max = 62.17125, 62.66875\n",
    "y_min, y_max = 62.3, 62.66875\n",
    "\n",
    "filtered_trollveggen = trollveggen[\n",
    "    (trollveggen[:, 0] >= x_min) & (trollveggen[:, 0] <= x_max) &\n",
    "    (trollveggen[:, 1] >= y_min) & (trollveggen[:, 1] <= y_max)\n",
    "]\n",
    "\n",
    "plt.scatter(filtered_trollveggen[:, 0],filtered_trollveggen[:, 1], c=filtered_trollveggen[:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21dc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jnp.unique(filtered_trollveggen[:, 0]).shape)\n",
    "print(jnp.unique(filtered_trollveggen[:, 1]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a29541",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = jnp.sort(jnp.unique(filtered_trollveggen[:, 0]))  \n",
    "x2 = jnp.sort(jnp.unique(filtered_trollveggen[:, 1]))  \n",
    "y_grid = jnp.zeros((len(x2), len(x1)))\n",
    "\n",
    "for i, row in enumerate(filtered_trollveggen):\n",
    "    ix = jnp.where(x1 == row[0])[0][0]\n",
    "    iy = jnp.where(x2 == row[1])[0][0]\n",
    "    y_grid = y_grid.at[iy, ix].set(row[2]) \n",
    "print(x1.shape, x2.shape, y_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_data, ax_data = plt.subplots(figsize=(10, 7))\n",
    "contour = ax_data.contour(x1, x2, y_grid, levels=15, colors=\"white\", alpha=0.3)\n",
    "contourf = ax_data.contourf(x1, x2, y_grid, levels=100)\n",
    "cbar = fig_data.colorbar(contourf, ax=ax_data, label=\"Elevation (m)\")\n",
    "ax_data.set_xlabel(\"Longitude\")\n",
    "ax_data.set_ylabel(\"Latitude\")\n",
    "ax_data.set_title(\"Grand Canyon Elevation Contour Map\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1542f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y_grid.flatten()\n",
    "# # y_norm = ( y - jnp.mean(y) ) / (jnp.max(y) - jnp.min(y))\n",
    "# # y_norm_grid = y_norm.reshape(89, 98)\n",
    "\n",
    "# x1_norm = ( x1 - jnp.mean(x1) ) / (jnp.max(x1) - jnp.min(x1))\n",
    "# x2_norm = ( x2 - jnp.mean(x2) ) / (jnp.max(x2) - jnp.min(x2))\n",
    "\n",
    "# X1_norm, X2_norm = jnp.meshgrid(x1_norm, x2_norm)\n",
    "# X_norm = jnp.column_stack((X1_norm.flatten(), X2_norm.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f835d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps = 1e-6\n",
    "\n",
    "# X1, X2 = jnp.meshgrid(x1, x2)\n",
    "# X = jnp.column_stack((X1.flatten(), X2.flatten()))\n",
    "# y_clean = y_grid.flatten().reshape(-1, 1)\n",
    "# y = jnp.where(y_clean < 0, 0, y_clean) + eps\n",
    "# y_log = jnp.log(y)\n",
    "# # y = y_clean + eps\n",
    "# X1_std = (X1.flatten() - jnp.mean(X1.flatten())) / jnp.std(X1.flatten())\n",
    "# X2_std = (X2 - jnp.mean(X2)) / jnp.std(X2)\n",
    "# X_std = jnp.column_stack((X1_std.flatten(), X2_std.flatten()))\n",
    "# print(jnp.min(X1_std), jnp.max(X1_std))\n",
    "# print(jnp.min(X2_std), jnp.max(X2_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece64a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-6\n",
    "X1, X2 = jnp.meshgrid(x1, x2)\n",
    "X = jnp.column_stack((X1.flatten(), X2.flatten()))\n",
    "X_std = (X - jnp.mean(X, axis=0)) / jnp.std(X, axis=0)\n",
    "\n",
    "y_clean = y_grid.flatten().reshape(-1, 1)\n",
    "y = jnp.where(y_clean < 0, 0, y_clean) + eps\n",
    "y_sqrt = jnp.sqrt(y)\n",
    "\n",
    "print(jnp.min(X_std, axis=0), jnp.max(X_std, axis=0))\n",
    "print(jnp.min(y_sqrt), jnp.max(y_sqrt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91091bb7",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Training-test \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_std, y_sqrt, test_size=0.2, random_state=42\n",
    "    )\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"2-7-7-7-1\"\n",
    "model = GPKAN(layers=[2, 7, 7, 1], \n",
    "              n_grid_points=10, \n",
    "              grid_min=jnp.min(X_std), \n",
    "              grid_max=jnp.max(X_std), \n",
    "              init_paramters=[1.0, 1.0],\n",
    "              obs_stddev=0.5\n",
    "              )\n",
    "\n",
    "def loss_ll(y_true, mean, covariance):\n",
    "    diag_elements = jnp.diag(covariance)\n",
    "    covariance_inv = jnp.diag(1.0 / diag_elements)\n",
    "    log_det = jnp.sum(jnp.log(diag_elements))\n",
    "    y_true = y_true.flatten()\n",
    "\n",
    "    return -(-0.5 * (\n",
    "        y_true.shape[0] * jnp.log(2 * jnp.pi) + \n",
    "        log_det + \n",
    "        (y_true - mean).T @ covariance_inv @ (y_true - mean)))\n",
    "\n",
    "val_grad_loss = jax.value_and_grad(\n",
    "    lambda Xs_latent, ys_latent, kernel_params, X_test, y_test:\n",
    "        loss_ll(y_test,\n",
    "                *model.sample_statistics(\n",
    "                    Xs_latent, ys_latent, X_test, kernel_params, n_samples=10)\n",
    "                ),\n",
    "                argnums=(0, 1, 2)\n",
    ")\n",
    "val_grad_loss = jax.jit(val_grad_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a23270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(epoch, initial_lr=0.0001):\n",
    "    return initial_lr * (0.95 ** (epoch//50))\n",
    "get_learning_rate = jax.jit(get_learning_rate)\n",
    "\n",
    "def clip_gradients(grads, max_norm=1.0):\n",
    "    grad_norm = jnp.sqrt(sum(jnp.sum(g**2) for g in jax.tree.leaves(grads)))\n",
    "    clip_factor = jnp.minimum(1.0, max_norm / grad_norm)\n",
    "    return jax.tree.map(lambda g: g * clip_factor, grads)\n",
    "clip_gradients = jax.jit(clip_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b87d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "epochs = 500\n",
    "# learning_rate = 0.0001\n",
    "learning_rate = 0.01\n",
    "loss_history = []\n",
    "\n",
    "batch_size = 32\n",
    "patience = 100  # Number of epochs to wait for improvement\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_losses = []\n",
    "    current_lr = get_learning_rate(epoch, initial_lr=learning_rate)\n",
    "\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        batch_X = X_train[i:i+batch_size, :]\n",
    "        batch_y = y_train[i:i+batch_size, :]\n",
    "\n",
    "        loss, (grad_grids, grad_supports, grad_params) = val_grad_loss(\n",
    "            model.latent_grids, \n",
    "            model.latent_supports,\n",
    "            model.kernel_parameters,\n",
    "            batch_X, batch_y\n",
    "            )\n",
    "        \n",
    "        # Stop training if loss becomes negative\n",
    "        if loss < 0 or jnp.isnan(loss):\n",
    "            print(f\"Stopping training at epoch {epoch} as loss became negative: {loss}\")\n",
    "            break \n",
    "\n",
    "        # grad_supports = clip_gradients(grad_supports)\n",
    "\n",
    "        model.latent_supports = jax.tree.map(\n",
    "            lambda latent_supports, grad_supports_: \n",
    "            latent_supports - grad_supports_ * current_lr,\n",
    "            model.latent_supports,\n",
    "            grad_supports\n",
    "        )\n",
    "\n",
    "        epoch_losses.append(loss)\n",
    "\n",
    "    # Check for improvement\n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        patience_counter = 0 \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}, best loss: {best_loss}\")\n",
    "        break\n",
    "\n",
    "    loss_history.append(epoch_loss)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss: {epoch_loss:.6f}, LR: {current_lr:.6f}\")\n",
    "    loss_history.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3739111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.01\n",
    "loss_history_params = []\n",
    "\n",
    "batch_size = 32\n",
    "patience = 100  # Number of epochs to wait for improvement\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_losses_params = []\n",
    "    current_lr = get_learning_rate(epoch, initial_lr=learning_rate)\n",
    "\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        batch_X = X_train[i:i+batch_size, :]\n",
    "        batch_y = y_train[i:i+batch_size, :]\n",
    "\n",
    "        loss, (grad_grids, grad_supports, grad_params) = val_grad_loss(\n",
    "            model.latent_grids, \n",
    "            model.latent_supports,\n",
    "            model.kernel_parameters,\n",
    "            batch_X, batch_y\n",
    "            )\n",
    "        \n",
    "        # Stop training if loss becomes negative\n",
    "        if loss < 0 or jnp.isnan(loss):\n",
    "            print(f\"Stopping training at epoch {epoch} as loss became negative: {loss}\")\n",
    "            break \n",
    "\n",
    "        grad_params = clip_gradients(grad_params)\n",
    "\n",
    "        model.kernel_parameters = jax.tree.map(\n",
    "            lambda kernel_params, grad_params_:\n",
    "            kernel_params - grad_params_ * current_lr,\n",
    "            model.kernel_parameters,\n",
    "            grad_params \n",
    "        )\n",
    "\n",
    "        epoch_losses_params.append(loss)\n",
    "\n",
    "    # Check for improvement\n",
    "    epoch_loss_params = np.mean(epoch_losses_params)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        patience_counter = 0 \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}, best loss: {best_loss}\")\n",
    "        break\n",
    "\n",
    "    loss_history_params.append(epoch_loss_params)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss: {epoch_loss_params:.6f}, LR: {current_lr:.6f}\")\n",
    "    loss_history.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_neurons(\n",
    "    # save_fig=True,\n",
    "    save_fig=False,\n",
    "    save_path=f\"figs/function_predictions/{function_name}/\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f165d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # Adjust as needed\n",
    "n = X_std.shape[0]\n",
    "mu_batches = []\n",
    "cov_blocks = []\n",
    "\n",
    "progress_interval = int(n * 0.05)\n",
    "for i in range(0, n, batch_size):\n",
    "    X_batch = X_std[i:i+batch_size]\n",
    "    mu_batch, cov_batch = model.sample_statistics(\n",
    "        model.latent_grids, model.latent_supports, X_batch, model.kernel_parameters, 5, key=jr.key(233 + i)\n",
    "    )\n",
    "    mu_batches.append(mu_batch)\n",
    "    cov_blocks.append(cov_batch)\n",
    "    if (i // batch_size) % (progress_interval // batch_size) == 0:\n",
    "        percent = int(100 * i / n)\n",
    "        print(f\"{percent}% done predicting...\")\n",
    "\n",
    "mu_full = jnp.concatenate(mu_batches)\n",
    "cov_full = jax.scipy.linalg.block_diag(*cov_blocks)\n",
    "y_stddev = jnp.sqrt(jnp.diag(cov_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_full = jnp.concatenate(mu_batches)\n",
    "cov_full = jax.scipy.linalg.block_diag(*cov_blocks)\n",
    "y_stddev = jnp.sqrt(jnp.diag(cov_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ebf3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# df_mu = pd.DataFrame(mu_full)\n",
    "# df_cov = pd.DataFrame(cov_full)\n",
    "\n",
    "# df_mu.to_csv(f\"figs/function_predictions/trollveggen/mu_nogradclip_{model_size}.csv\")\n",
    "# df_cov.to_csv(f\"figs/function_predictions/trollveggen/cov_nogradclip_{model_size}.csv\")\n",
    "\n",
    "df_mu = pd.read_csv(\"figs/function_predictions/trollveggen/mu_nogradclip.csv\", index_col=False)\n",
    "df_cov = pd.read_csv(\"figs/function_predictions/trollveggen/cov_nogradclip.csv\", index_col=False)\n",
    "\n",
    "mu_full = jnp.array(df_mu.values[:, 1:])\n",
    "cov_full = jnp.array(df_cov.values[:, 1:])\n",
    "y_stddev = jnp.sqrt(jnp.diag(cov_full))\n",
    "print(mu_full.shape, cov_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu, cov = model.sample_statistics(model.latent_grids, model.latent_supports, X_norm, model.kernel_parameters, 5, key=jr.key(233))\n",
    "residuals = y_sqrt.flatten() - mu_full.flatten()\n",
    "# y_sample = jr.multivariate_normal(jr.key(2341), mu, cov, shape=(1, )).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a060a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(22, 5))\n",
    "\n",
    "# Determine the min/max values across both datasets to create a consistent color scale\n",
    "vmin = min(y_sqrt.min(), mu_full.min())\n",
    "vmax = max(y_sqrt.max(), mu_full.max())\n",
    "\n",
    "contourf_test = axs[0].contourf(x1, x2, y_sqrt.reshape(x2.shape[0], x1.shape[0]),  \n",
    "                                levels=50,\n",
    "                                cmap=\"viridis\",\n",
    "                                vmin=vmin,\n",
    "                                vmax=vmax\n",
    "                                )\n",
    "\n",
    "axs[0].set_title(\"Actual Function\")\n",
    "axs[0].set_xlabel(\"x\")\n",
    "axs[0].set_ylabel(\"y\")\n",
    "fig.colorbar(contourf_test, ax=axs[0])\n",
    "\n",
    "contourf_pred = axs[1].contourf(x1, x2, mu_full.reshape(x2.shape[0], x1.shape[0]), \n",
    "                                cmap=\"viridis\",\n",
    "                                levels=50,\n",
    "                                vmin=vmin,\n",
    "                                vmax=vmax)\n",
    "axs[1].set_title(\"Approximated Mean Function\")\n",
    "axs[1].set_xlabel(\"x\")\n",
    "axs[1].set_ylabel(\"y\")\n",
    "fig.colorbar(contourf_pred, ax=axs[1])\n",
    "\n",
    "contourf_res = axs[2].contourf(x1, x2, \n",
    "                               jnp.abs(residuals).reshape(x2.shape[0], x1.shape[0]), \n",
    "                               levels=100, cmap=\"jet\")\n",
    "axs[2].set_title(\"Residuals\")\n",
    "axs[2].set_xlabel(\"x\")\n",
    "axs[2].set_ylabel(\"y_sqrt\")\n",
    "fig.colorbar(contourf_res, ax=axs[2])\n",
    "\n",
    "contourf_var = axs[3].contourf(x1, x2, y_stddev.reshape(x2.shape[0], x1.shape[0]), \n",
    "                                levels=100, cmap=\"jet\")\n",
    "fig.colorbar(contourf_var, ax=axs[3])\n",
    "axs[3].set_title(\"Standard deviation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fafc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jnp.min(y_stddev), jnp.max(y_stddev))\n",
    "print(jnp.min(mu_full), jnp.max(mu_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = jnp.mean(jnp.abs(residuals))\n",
    "print(\"Mean Absolute Deviation (MAD):\", mad)\n",
    "\n",
    "pointwise_mad = jnp.concatenate([jnp.sqrt(jnp.diag(cov)) for cov in cov_blocks])\n",
    "print(\"Pointwise Mean Absolute Deviation (from predictive stddev):\", jnp.mean(pointwise_mad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e787f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_std = jnp.sort(jnp.unique(X_std[:, 0]))\n",
    "x2_std = jnp.sort(jnp.unique(X_std[:, 1])) \n",
    "print(jnp.min(x1_std), jnp.max(x1_std))\n",
    "print(jnp.min(x2_std), jnp.max(x2_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ae3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=(5,5))\n",
    "q = ax2.contourf(x1_std, x2_std, pointwise_mad.reshape(x2_std.shape[0], x1_std.shape[0]), \n",
    "                                levels=50,\n",
    "                                cmap=\"viridis\",\n",
    "                                )\n",
    "fig2.colorbar(q, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10), constrained_layout=True)\n",
    "axs = axs.flatten()\n",
    "function_name = \"åndalsnes\"\n",
    "\n",
    "# Determine the min/max values for the original function and mean\n",
    "vmin = min(y_sqrt.min(), mu_full.min())\n",
    "vmax = max(y_sqrt.max(), mu_full.max())\n",
    "norm1 = plt.Normalize(vmin, vmax)\n",
    "\n",
    "# First plot - Actual Function (unchanged)\n",
    "\n",
    "contourf_test = axs[0].contourf(x1_std, x2_std, y_sqrt.reshape(x2_std.shape[0], x1_std.shape[0]), \n",
    "                                levels=50,\n",
    "                                cmap=\"viridis\",\n",
    "                                vmin=vmin,\n",
    "                                vmax=vmax\n",
    "                                )\n",
    "\n",
    "axs[0].set_title(\"Underlying data\")\n",
    "axs[0].set_xlabel(\"$x_1$\")\n",
    "axs[0].set_ylabel(\"$x_2$\")\n",
    "\n",
    "contourf_pred = axs[1].contourf(x1_std, x2_std, mu_full.reshape(x2_std.shape[0], x1_std.shape[0]), \n",
    "                                cmap=\"viridis\",\n",
    "                                levels=50,\n",
    "                                vmin=vmin,\n",
    "                                vmax=vmax\n",
    "                                )\n",
    "                                \n",
    "axs[1].set_title(\"Approximated Mean Function\")\n",
    "axs[1].set_xlabel(\"$x_1$\")\n",
    "axs[1].set_ylabel(\"$x_2$\")\n",
    "\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import numpy as np\n",
    "sm1 = ScalarMappable(cmap=\"viridis\", norm=norm1)\n",
    "sm1.set_array([])  # Empty array - using the norm instead\n",
    "cbar_row1 = fig.colorbar(sm1, ax=[axs[0], axs[1]], location='right', shrink=0.98)\n",
    "cbar_row1.set_label(\"Function value\")\n",
    "\n",
    "# Create evenly spaced ticks for the first colorbar\n",
    "n_ticks = 9  # Number of ticks including min and max\n",
    "ticks1 = np.linspace(vmin, vmax, n_ticks)\n",
    "cbar_row1.set_ticks(ticks1)\n",
    "cbar_row1.set_ticklabels([f\"{tick:.2f}\" for tick in ticks1])  # Format to 2 decimal places)  # Optional: ensure min/max are shown\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Third plot - Normalized Residuals (as percentage of mean)\n",
    "reshaped_residuals = residuals.reshape(x2_std.shape[0], x1_std.shape[0])\n",
    "epsilon = 1e-10\n",
    "normalized_residuals = 100 * jnp.abs(reshaped_residuals.flatten()) / (jnp.abs(mu_full.flatten()) + epsilon)\n",
    "normalized_stddev = 100 * (y_stddev.flatten() / (jnp.abs(mu_full.flatten()) + epsilon))\n",
    "\n",
    "vmin_2 = min(normalized_residuals.min(), normalized_stddev.min())\n",
    "vmax_2 = max(normalized_residuals.max(), normalized_stddev.max())\n",
    "cbar_limit = 250 \n",
    "levels = np.linspace(vmin_2, cbar_limit, 20)\n",
    "# levels = np.arange(vmin_2, cbar_limit, 25)\n",
    "\n",
    "contourf_std_res = axs[2].contourf(x1_std, x2_std, normalized_residuals.reshape(x2_std.shape[0], x1_std.shape[0]), \n",
    "                               levels=levels, \n",
    "                               cmap=\"jet\",\n",
    "                               vmin=vmin_2,\n",
    "                               vmax=cbar_limit,\n",
    "                               extend=\"max\",\n",
    "                               )\n",
    "\n",
    "axs[2].set_title(\"Normalized Residuals\")\n",
    "axs[2].set_xlabel(\"$x_1$\")\n",
    "axs[2].set_ylabel(\"$x_2$\")\n",
    "\n",
    "contourf_std_var = axs[3].contourf(x1_std, x2_std, normalized_stddev.reshape(x2_std.shape[0], x1_std.shape[0]), \n",
    "                                # levels=50, \n",
    "                                levels=levels,\n",
    "                                cmap=\"jet\",\n",
    "                                vmin=vmin_2,\n",
    "                                vmax=cbar_limit,\n",
    "                                extend=\"max\",\n",
    "                                )\n",
    "                                \n",
    "axs[3].set_title(\"Normalized Uncertainty\")\n",
    "# axs[3].set_title(\"Coefficient of Variation\")\n",
    "axs[3].set_xlabel(\"$x_1$\")\n",
    "axs[3].set_ylabel(\"$x_2$\")\n",
    "\n",
    "# norm2 = plt.Normalize(vmin_2, vmax_2)  # Create explicit normalization\n",
    "norm2 = plt.Normalize(vmin_2, cbar_limit)  # Create explicit normalization\n",
    "sm2 = ScalarMappable(cmap=\"jet\", norm=norm2)\n",
    "sm2.set_array([])  # Empty array - using the norm instead\n",
    "cbar_row2 = fig.colorbar(sm2, ax=[axs[2], axs[3]], location='right', shrink=0.98, extend=\"max\")\n",
    "cbar_row2.set_label('Relative Error (\\%)')\n",
    "\n",
    "# Create evenly spaced ticks for the first colorbar\n",
    "n_ticks = 9 # Number of ticks including min and max\n",
    "# ticks2 = np.linspace(vmin_2, vmax_2, n_ticks)\n",
    "# ticks2 = np.linspace(vmin_2, cbar_limit, n_ticks)\n",
    "# ticks2 = np.linspace(0, cbar_limit, n_ticks)\n",
    "ticks2 = np.arange(0, cbar_limit + 1, 25)\n",
    "cbar_row2.set_ticks(ticks2)\n",
    "# cbar_row2.set_ticklabels([f\"{tick:.1f}\" for tick in ticks2])\n",
    "cbar_row2.set_ticklabels([f\"{tick}\" for tick in ticks2])\n",
    "\n",
    "# fig.suptitle(\"Åndalsnes and Romsdalen ($\\sqrt{y}$-transformed)\", fontsize=25)\n",
    "fig.suptitle(\"Åndalsnes and Romsdalen\", fontsize=30, fontweight=\"bold\")\n",
    "\n",
    "# plt.subplots_adjust(top=0.88)\n",
    "plt.savefig(f\"figs/function_predictions/{function_name}/{function_name}_NORAposter.png\", dpi=500, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_residual_idx = jnp.argmax(normalized_residuals)\n",
    "max_stddev_idx = jnp.argmax(normalized_stddev)\n",
    "print(\"Index of max normalized_residuals:\", max_residual_idx)\n",
    "print(\"Index of max normalized_stddev:\", max_stddev_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74172241",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalized_residuals[max_residual_idx])\n",
    "print(mu_full[max_residual_idx])\n",
    "print(y_stddev[max_residual_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd5eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test.flatten(), cmap='viridis', s=15)\n",
    "plt.colorbar(label='y_test')\n",
    "plt.xlabel('x1 (standardized)')\n",
    "plt.ylabel('x2 (standardized)')\n",
    "plt.title('Test Set Locations (Missing Data)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
